{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8100bc0",
   "metadata": {},
   "source": [
    "# Create a classification dataset (n samples >=1000, n features >= 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f8053c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import warnings \n",
    "warnings.filterwarnings(action= 'ignore')\n",
    "\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87140972",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = datasets.make_classification(n_samples = 1000, n_features=10,\n",
    "                                      n_informative=2, n_redundant=2, n_repeated=0, n_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5e0703c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.45106504  2.35844646 -0.42580449 ...  0.25853585  1.23656221\n",
      "   0.17026124]\n",
      " [ 1.30765676 -0.64186476 -0.26412823 ...  0.76528904 -0.01720867\n",
      "  -1.78642488]\n",
      " [ 0.82030017 -1.31823807 -1.41528935 ... -0.13605011  0.96512672\n",
      "   0.86765957]\n",
      " ...\n",
      " [-0.09907717  0.71196792 -1.2546767  ...  0.38838781  2.12775475\n",
      "  -0.01953667]\n",
      " [ 1.01263164 -0.39987046  0.73796287 ...  0.65802434  0.52980371\n",
      "  -0.29193672]\n",
      " [ 2.0472248  -1.63423083  0.07260973 ...  0.77461098 -0.35937675\n",
      "  -1.38259724]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b21eccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 0 1 1 1 1 1 1 0 0 0 0 0 1 0 1 1 1 0 0 0 1 0 1 0 1 0 1 0 0 0 0 1 0 0\n",
      " 1 1 1 0 1 1 1 1 0 1 1 1 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 1 0 0 1 0 0 0 0 0 1\n",
      " 0 0 0 0 0 1 1 1 1 1 1 0 0 1 0 1 0 1 0 0 1 0 0 1 1 1 1 1 0 0 1 0 0 0 0 0 1\n",
      " 0 0 1 1 0 1 0 1 0 0 1 1 1 0 1 1 1 1 0 1 1 0 1 0 0 0 1 1 1 1 0 0 0 1 1 0 0\n",
      " 0 1 0 1 0 0 1 1 0 1 0 1 1 1 0 1 1 0 0 0 0 0 1 1 1 1 0 1 1 0 0 0 0 1 1 0 1\n",
      " 0 0 0 0 1 0 0 1 0 0 1 0 0 0 1 0 1 1 0 1 0 0 0 1 1 0 0 1 1 0 0 0 0 0 0 0 1\n",
      " 1 1 1 1 0 1 0 0 0 1 0 0 1 0 1 1 0 1 1 0 0 1 0 0 1 0 1 1 1 1 1 1 0 0 0 0 1\n",
      " 0 1 0 1 1 1 0 1 0 0 1 1 0 0 0 0 0 0 0 1 1 1 1 0 0 0 1 1 1 1 0 1 1 1 1 1 1\n",
      " 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 1 1 1 1 0 0 0 1 1 0 1 1\n",
      " 1 0 0 0 0 0 1 0 0 1 1 1 0 0 0 0 1 0 0 1 0 0 1 1 0 0 1 0 1 1 1 1 0 0 0 0 1\n",
      " 0 0 1 1 0 0 1 1 1 1 1 0 1 1 0 0 0 0 1 0 0 0 0 1 0 1 0 1 1 1 1 0 1 1 0 0 0\n",
      " 1 1 1 1 0 0 1 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 1 0 1 0 1 1 0 1 1\n",
      " 1 1 0 1 0 1 1 0 0 1 1 0 1 0 1 0 1 0 0 1 1 0 0 0 1 0 0 0 1 1 1 1 1 1 1 1 0\n",
      " 1 0 1 1 1 0 0 1 0 1 0 1 1 1 0 0 0 0 1 0 1 1 0 0 1 0 1 1 1 0 1 1 1 1 0 0 1\n",
      " 0 1 0 1 0 1 0 0 1 0 1 1 0 1 1 0 1 1 0 1 1 0 0 1 0 1 1 0 0 0 1 0 1 1 1 1 0\n",
      " 1 1 0 1 0 1 1 0 1 1 0 0 1 0 0 1 0 1 1 0 0 1 1 0 1 1 0 1 1 1 1 1 0 0 0 1 0\n",
      " 0 1 0 1 0 0 0 0 0 0 1 0 1 1 0 1 1 1 1 0 0 1 0 1 0 0 1 1 0 1 1 1 1 0 1 0 1\n",
      " 0 0 0 1 0 0 1 1 0 1 1 1 1 1 0 0 1 0 1 1 1 0 1 1 1 1 1 0 1 0 1 0 0 0 0 0 1\n",
      " 1 0 1 1 1 1 1 0 0 1 1 1 1 0 1 0 0 1 1 1 0 1 1 1 0 1 1 0 0 1 1 0 0 1 1 0 1\n",
      " 0 0 1 1 0 0 0 0 0 1 1 0 0 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 0\n",
      " 0 0 0 0 1 1 1 1 0 0 1 0 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 1 1 0 0\n",
      " 0 1 1 0 1 1 0 1 1 1 1 0 0 0 1 1 1 1 0 0 0 1 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 1 1 1 1 0 0 0 1 0 1 0 1 1 1 0 1 1 1 0 1 1 0 1 0 0 1 1 1 0 1 0 1 1 1 1 0 1\n",
      " 1 1 1 1 0 1 0 1 1 0 0 1 0 0 1 0 1 0 1 1 0 0 0 0 1 1 0 0 0 1 1 0 1 0 0 1 1\n",
      " 0 0 1 1 0 1 0 0 0 0 1 1 1 1 1 0 1 1 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 1 0 1 0\n",
      " 1 1 0 1 1 0 0 0 0 0 0 0 1 1 1 0 1 0 0 1 0 0 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1\n",
      " 0 0 1 0 0 0 0 0 0 1 0 1 1 0 1 1 0 1 1 1 0 1 1 0 1 0 1 0 0 1 0 0 0 0 1 1 1\n",
      " 1]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85b83d8",
   "metadata": {},
   "source": [
    "# Split the dataset to 40% for data test and 60% Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f30a6961",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da4efe92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of original dataset : [[-1.45106504  2.35844646 -0.42580449 ...  0.25853585  1.23656221\n",
      "   0.17026124]\n",
      " [ 1.30765676 -0.64186476 -0.26412823 ...  0.76528904 -0.01720867\n",
      "  -1.78642488]\n",
      " [ 0.82030017 -1.31823807 -1.41528935 ... -0.13605011  0.96512672\n",
      "   0.86765957]\n",
      " ...\n",
      " [-0.09907717  0.71196792 -1.2546767  ...  0.38838781  2.12775475\n",
      "  -0.01953667]\n",
      " [ 1.01263164 -0.39987046  0.73796287 ...  0.65802434  0.52980371\n",
      "  -0.29193672]\n",
      " [ 2.0472248  -1.63423083  0.07260973 ...  0.77461098 -0.35937675\n",
      "  -1.38259724]] (1000,)\n",
      "shape of input - training set (600, 10)\n",
      "shape of output - training set (600,)\n",
      "shape of input - testing set (400, 10)\n",
      "shape of output - testing set (400,)\n"
     ]
    }
   ],
   "source": [
    "print(\"shape of original dataset :\", X,y.shape)\n",
    "print(\"shape of input - training set\", X_train.shape)\n",
    "print(\"shape of output - training set\", y_train.shape)\n",
    "print(\"shape of input - testing set\", X_test.shape)\n",
    "print(\"shape of output - testing set\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d060200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.10763223  0.73464429  2.39040967 ...  0.39581468  1.3088443\n",
      "  -0.95351726]\n",
      " [ 1.06668189 -1.39049148  0.77178974 ...  0.04090152  0.11596665\n",
      "  -0.37886706]\n",
      " [ 0.98911943 -1.45987449 -0.75245944 ... -0.07679918  0.15420001\n",
      "   1.09459199]\n",
      " ...\n",
      " [ 0.54219693 -1.19134003  1.49035009 ... -0.30527264 -0.27981774\n",
      "  -1.63736129]\n",
      " [ 1.85208329 -1.49094601 -0.56402652 ...  0.69237022 -1.53505805\n",
      "  -2.34102664]\n",
      " [ 1.37764277 -1.04003537 -0.78040824 ...  0.56142735  0.44580732\n",
      "   1.56298631]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6baadbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.17536628 -0.78278437  0.52370147 ... -0.36619583  0.24525337\n",
      "   0.94441477]\n",
      " [ 0.66201667 -0.34712359  0.65760669 ...  0.37251666  0.19540079\n",
      "  -0.85594092]\n",
      " [ 0.10022577  0.87421586  0.11628864 ...  0.68003742  0.69137547\n",
      "  -1.75084664]\n",
      " ...\n",
      " [ 0.21389947  0.00756268  1.48009063 ...  0.20092261  0.36694038\n",
      "  -1.40107715]\n",
      " [ 0.41440434 -0.20602643 -1.19866359 ...  0.24076464  1.46076223\n",
      "  -0.60610224]\n",
      " [-1.63740302  1.38754742 -1.05676628 ... -0.56540073  0.71908608\n",
      "  -0.54071244]]\n"
     ]
    }
   ],
   "source": [
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a440e3b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 1 1 1 0 1 1 0 1 0 1 1 0 0 1 0 1 0 1 1 0 1 0 0 0 1 0 0 1 1 0 1 0 0 1\n",
      " 1 0 1 1 1 0 1 0 1 0 0 1 1 0 1 0 1 0 0 0 0 0 0 1 1 1 1 0 0 1 1 1 0 0 0 0 1\n",
      " 0 0 0 0 0 1 1 0 1 0 0 1 1 1 1 0 1 0 0 1 1 0 1 0 1 0 1 1 0 0 1 1 0 1 1 1 0\n",
      " 0 1 1 0 0 0 1 1 1 1 1 0 1 1 0 1 1 0 0 1 0 1 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0\n",
      " 1 1 1 0 0 1 1 1 0 0 1 0 0 0 0 1 1 0 0 1 0 1 1 1 1 0 1 0 1 0 1 1 0 1 1 1 1\n",
      " 1 1 1 1 1 0 1 1 0 0 0 1 0 0 0 0 1 1 1 0 1 1 1 1 0 1 1 1 0 0 1 1 0 1 1 0 1\n",
      " 0 0 0 0 0 0 1 1 0 1 0 0 1 0 0 1 1 1 0 0 1 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0 1\n",
      " 0 1 0 1 0 0 0 1 0 0 0 0 1 1 0 1 1 0 0 0 1 0 1 1 0 1 1 0 0 0 1 0 1 0 0 0 0\n",
      " 1 1 0 0 1 0 0 1 0 1 1 0 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 1 1 0 0 0 1 0\n",
      " 1 1 1 0 0 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 1 0\n",
      " 0 0 0 1 0 0 0 1 1 0 0 0 1 0 1 1 0 1 1 0 1 0 1 1 0 1 0 0 0 1 0 0 0 1 0 0 1\n",
      " 0 0 1 1 0 0 0 1 1 0 0 1 1 0 0 0 0 1 1 1 0 1 0 1 1 0 1 1 0 1 1 0 0 1 1 1 1\n",
      " 0 1 0 0 0 0 0 1 1 1 1 1 0 0 1 0 1 1 0 0 0 1 1 0 0 1 0 1 1 0 0 0 1 0 1 1 1\n",
      " 1 1 1 0 0 1 1 0 1 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 1 1 1 1 1 0 1 1\n",
      " 1 0 1 0 0 1 1 0 1 0 1 1 0 0 1 1 1 0 0 0 1 1 1 0 1 1 0 1 1 1 1 0 0 1 0 0 1\n",
      " 0 0 1 0 0 0 0 1 0 0 1 0 1 1 1 0 1 1 0 1 0 0 1 0 1 0 0 0 1 1 1 0 0 1 0 1 1\n",
      " 1 1 1 1 0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0dabcfe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 0 0 0 1 0 1 0 1 1 1 1 0 0 1 1 0 0 0 0 0 1 0 1 0 1 1 1 1 1 0 0 0 1 1\n",
      " 0 1 0 1 1 1 0 0 1 1 0 1 1 1 0 0 1 1 1 1 1 0 1 1 1 0 0 1 0 0 0 0 1 0 0 0 1\n",
      " 1 1 1 0 0 0 0 1 0 0 0 0 0 0 1 1 1 0 0 1 0 1 0 0 0 0 1 1 1 0 0 0 1 0 0 1 0\n",
      " 0 0 0 1 1 0 1 0 1 1 0 0 1 0 1 0 0 1 0 0 0 0 0 0 1 1 0 1 0 1 1 0 0 1 1 1 0\n",
      " 1 1 1 1 1 0 1 0 1 1 1 1 0 0 1 0 1 1 1 1 1 1 1 0 1 0 0 0 1 0 1 0 1 1 0 0 1\n",
      " 0 0 1 1 1 1 0 1 1 0 0 0 1 0 0 1 1 1 1 0 0 0 1 1 0 1 1 1 1 0 1 0 1 1 1 0 0\n",
      " 0 0 0 1 1 0 0 1 1 0 1 0 1 1 0 1 1 0 1 1 1 0 0 1 1 0 0 0 0 0 1 1 1 0 0 1 0\n",
      " 1 1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 0 1 0 0 0 0 1 1 0 1 0 0 0 1 0 1 1 0 1 1 0\n",
      " 0 1 1 1 1 1 0 1 0 1 0 1 1 0 0 1 0 0 1 1 1 0 1 1 0 0 1 1 0 0 1 1 0 1 0 1 0\n",
      " 0 1 0 1 0 1 0 1 0 1 0 1 0 1 1 1 1 1 1 0 1 1 1 0 0 0 1 0 1 1 0 0 0 1 0 1 1\n",
      " 1 0 0 1 1 0 0 1 1 1 1 1 1 0 1 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ace11cc",
   "metadata": {},
   "source": [
    "# Train The Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "718e7494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 0 0 1 1 1 1 0 1 1 1 1 0 0 1 1 0 0 0 0 0 1 0 1 0 1 1 1 1 1 1 0 0 1 1\n",
      " 0 1 0 1 1 1 0 0 1 1 0 1 1 1 0 0 1 1 1 0 1 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 1\n",
      " 1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 1 0 0 0 0 1 1 1 0 0 0 1 0 0 1 1\n",
      " 0 0 0 1 1 0 1 0 1 1 0 0 1 0 1 0 0 1 0 0 0 0 0 0 1 1 0 1 0 1 1 0 0 1 1 1 0\n",
      " 1 1 1 1 0 0 1 0 0 1 1 1 0 0 1 0 1 1 1 1 1 1 0 0 1 0 0 0 1 0 1 0 1 1 0 0 1\n",
      " 0 0 1 1 1 1 0 1 1 0 0 0 1 0 0 1 1 1 1 0 0 0 1 1 0 1 1 1 0 0 1 0 1 1 1 0 0\n",
      " 0 0 0 1 1 0 0 1 1 0 1 0 1 1 0 1 1 0 1 1 1 0 0 0 1 0 0 0 0 0 1 1 1 0 0 1 0\n",
      " 1 1 0 1 0 0 1 0 0 0 1 0 1 1 1 1 0 1 0 0 0 0 1 1 0 1 0 0 0 1 0 1 1 0 1 1 0\n",
      " 0 1 1 1 1 1 1 1 0 1 0 1 1 0 0 1 0 0 1 1 1 0 1 1 0 0 1 1 0 0 1 1 0 1 0 1 0\n",
      " 0 1 0 1 0 1 0 0 0 1 0 1 1 1 0 1 1 1 1 0 1 1 1 0 0 1 1 0 1 1 0 0 0 1 0 1 1\n",
      " 1 0 0 0 1 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "#Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "model1 = GaussianNB()\n",
    "model1.fit(X_train, y_train)\n",
    "predict = model1.predict(X_test)\n",
    "print(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eaa4931f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 1 1 0 0 1 1 0 1 0 1 1 1 1 0 0 0 1 0 0 0 0 0 1 0 1 0 1 1 1 1 1 1 0 0 1 1\n",
      " 0 1 0 1 1 1 0 0 1 1 0 1 1 1 0 0 1 1 1 0 1 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 1\n",
      " 1 0 1 0 0 1 0 1 0 0 0 0 0 0 1 1 1 0 0 1 0 1 0 0 0 0 1 1 1 0 0 0 1 0 0 1 1\n",
      " 0 0 0 1 1 0 1 0 1 1 0 0 1 0 1 0 0 1 0 0 0 0 0 0 1 1 0 1 0 1 1 0 0 1 1 1 0\n",
      " 1 1 1 1 0 0 1 0 0 1 1 1 0 0 1 0 1 1 1 1 1 1 0 0 1 0 0 0 1 0 1 0 1 1 0 0 1\n",
      " 0 0 1 1 1 1 0 1 1 0 0 0 1 0 0 1 1 1 1 0 0 0 1 1 0 1 1 1 0 0 1 0 1 1 1 0 0\n",
      " 0 0 0 1 1 0 0 1 1 0 1 0 1 1 0 1 1 0 1 1 1 0 0 1 1 0 0 0 0 0 1 1 1 0 0 1 0\n",
      " 1 1 0 1 0 0 1 0 0 0 1 0 1 1 1 1 0 1 0 0 0 0 1 1 0 1 0 0 0 1 0 1 1 0 1 1 0\n",
      " 0 1 1 1 1 1 1 1 0 1 0 1 1 0 0 1 0 0 1 1 1 0 1 1 0 0 1 1 0 0 1 1 0 1 0 1 0\n",
      " 0 1 0 1 0 1 0 0 0 1 0 1 1 1 0 1 1 1 1 0 1 1 1 0 0 0 1 0 1 1 0 0 0 1 0 1 1\n",
      " 1 0 0 0 1 0 0 0 0 1 1 1 1 0 1 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0]\n",
      "[0 1 1 0 0 1 1 0 1 0 1 1 1 1 0 0 1 1 0 0 0 0 0 1 0 1 0 1 1 1 1 0 1 0 0 1 1\n",
      " 0 1 0 1 1 1 0 0 1 1 0 1 1 1 0 0 1 1 1 0 1 0 1 1 1 0 0 1 0 0 0 0 0 0 0 0 1\n",
      " 1 0 1 0 0 0 0 1 0 0 1 0 0 0 1 1 1 0 0 1 1 1 0 0 0 0 1 1 1 0 0 0 1 0 0 1 0\n",
      " 0 0 0 1 1 0 1 0 1 1 0 0 1 0 1 0 0 1 0 0 0 0 0 0 1 1 0 1 0 1 1 0 0 1 1 1 0\n",
      " 1 1 1 1 0 0 1 0 0 1 1 1 0 0 1 0 1 1 1 1 1 1 1 0 1 0 0 0 1 0 1 0 1 1 0 0 1\n",
      " 0 0 1 1 1 1 0 1 1 0 0 0 1 0 0 1 1 1 1 0 0 0 1 1 0 1 1 1 0 0 1 0 1 1 1 0 0\n",
      " 0 0 0 1 1 0 0 1 1 0 1 0 1 1 0 1 1 0 1 1 1 0 0 1 1 0 0 0 0 0 1 1 1 0 0 1 0\n",
      " 1 1 0 1 0 0 1 0 0 0 1 0 1 1 1 1 0 1 0 0 0 0 1 1 0 1 0 0 0 1 0 1 1 0 1 1 0\n",
      " 0 1 1 1 1 1 1 1 0 1 0 1 1 0 0 1 0 0 1 1 1 0 1 1 0 0 1 1 0 0 1 1 0 1 0 1 0\n",
      " 0 1 0 1 0 1 0 0 0 1 0 1 0 1 0 1 1 1 1 0 1 1 1 0 0 0 1 0 1 1 0 0 0 1 0 1 1\n",
      " 1 0 0 0 1 0 0 0 1 1 1 1 1 0 1 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0]\n",
      "[0 1 1 0 0 1 1 0 1 0 1 1 1 1 0 0 0 1 0 0 0 0 0 1 0 1 0 1 1 1 1 0 1 0 0 1 1\n",
      " 0 1 0 1 1 1 0 0 1 1 0 1 1 1 0 0 1 1 1 0 1 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 1\n",
      " 1 1 1 0 0 0 0 1 0 0 1 0 0 0 1 1 1 0 0 1 0 1 0 0 0 0 1 1 1 0 0 0 1 0 0 1 0\n",
      " 0 0 0 1 1 0 1 0 1 1 0 0 1 0 1 0 0 1 0 0 0 0 0 0 1 1 1 1 0 1 1 0 0 1 1 1 0\n",
      " 1 1 0 1 0 0 1 0 1 1 1 1 0 0 1 0 1 1 1 1 1 1 1 0 1 0 0 0 1 0 1 0 1 0 0 0 1\n",
      " 0 0 1 1 1 1 0 1 1 0 0 0 1 0 0 1 1 1 1 0 0 0 1 1 0 1 1 1 0 0 1 0 1 1 1 0 0\n",
      " 0 0 0 1 1 0 0 1 1 0 1 0 1 1 0 1 1 0 1 1 1 0 0 1 1 0 0 0 0 0 1 1 1 0 0 1 0\n",
      " 1 1 0 1 0 0 1 0 0 0 1 0 0 1 1 1 0 1 0 1 0 0 1 1 0 1 0 0 0 1 0 1 1 0 1 1 0\n",
      " 0 1 1 1 1 1 1 1 0 1 0 1 1 0 0 1 0 0 1 1 1 0 1 1 0 0 1 1 0 0 1 1 0 0 0 1 0\n",
      " 0 1 0 1 0 1 0 0 0 1 0 0 0 1 0 1 1 1 1 0 1 1 1 0 0 0 1 0 1 1 0 0 0 1 0 1 1\n",
      " 1 0 0 0 1 0 0 1 0 1 1 1 1 0 1 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0]\n",
      "[0 1 1 0 0 1 1 0 1 0 1 1 1 1 0 0 0 1 0 0 0 0 0 0 0 1 0 1 1 1 1 0 1 0 0 1 1\n",
      " 0 1 0 1 1 1 0 0 1 1 0 1 1 1 0 0 1 1 1 1 1 0 1 0 1 0 0 1 0 0 0 0 0 0 0 1 1\n",
      " 1 1 1 0 0 0 0 1 0 0 0 0 0 0 1 1 1 0 0 1 0 1 0 0 0 0 1 1 1 0 0 0 1 0 0 1 0\n",
      " 0 0 0 1 1 0 1 0 1 1 0 0 1 0 1 0 0 1 0 0 0 0 0 0 1 1 1 1 0 1 1 0 0 1 1 1 0\n",
      " 1 0 1 1 1 0 1 0 1 1 1 0 0 0 1 0 1 1 1 1 1 1 1 0 1 0 1 0 1 0 1 0 1 0 0 0 1\n",
      " 0 0 1 1 1 1 0 1 1 0 0 0 1 0 0 1 1 1 1 0 0 0 1 1 0 1 1 1 0 0 1 0 1 1 1 0 0\n",
      " 0 0 0 1 1 0 0 1 1 0 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 0 0 0 0 0 1 1 0 0 0 1 0\n",
      " 1 0 0 1 0 0 1 0 0 0 1 0 0 1 1 1 0 1 0 0 0 0 1 1 0 1 0 0 0 1 0 1 1 0 1 1 0\n",
      " 0 1 1 1 1 1 0 1 0 1 0 1 1 0 0 1 0 0 1 1 1 0 1 1 0 0 1 1 0 0 1 1 0 1 0 1 0\n",
      " 0 1 0 1 0 1 0 0 0 1 0 1 0 0 0 1 1 1 1 0 1 1 1 0 0 0 1 0 1 1 0 0 0 0 0 1 1\n",
      " 1 0 0 0 1 0 0 1 0 1 0 1 1 0 1 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "#SVC (possible values of C [1e-02, 1e-01, 1e00, 1e01, 1e02], RBF kernel)\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "for num in  [1e-02, 1e-01, 1e00, 1e01, 1e02]:\n",
    "    model2= SVC(num, kernel='rbf', gamma=0.1)\n",
    "    model2.fit(X_train, y_train)\n",
    "    predict2 = model2.predict(X_test)\n",
    "    print(predict2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f84c3060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 0 0 1 1 0 1 0 1 1 1 1 0 0 0 1 0 0 0 0 0 1 0 1 0 1 1 1 1 0 0 0 0 1 1\n",
      " 0 1 0 1 1 1 0 0 1 1 0 1 1 1 0 0 0 1 1 1 1 0 1 1 1 0 0 1 0 0 0 0 0 0 0 0 1\n",
      " 1 0 1 0 0 1 0 1 0 0 1 0 0 0 0 1 1 0 0 1 0 1 0 0 0 0 1 1 1 0 0 0 1 0 0 1 0\n",
      " 0 0 0 1 1 0 1 0 1 1 0 0 1 0 1 0 0 1 0 0 0 0 0 0 1 1 0 1 0 1 1 0 0 1 1 1 0\n",
      " 1 1 1 1 0 0 1 0 1 1 1 1 0 0 1 0 1 1 1 1 1 1 1 0 1 0 0 0 1 0 1 0 1 1 0 0 1\n",
      " 0 1 1 1 1 1 0 1 1 0 0 0 1 0 0 1 1 1 1 0 0 0 1 1 0 1 1 1 0 0 1 0 1 1 1 0 0\n",
      " 0 0 0 1 1 0 0 1 1 0 1 0 1 1 0 1 1 0 1 1 1 0 0 1 1 0 0 0 0 0 1 1 1 0 0 1 0\n",
      " 1 1 0 1 0 0 1 0 0 0 1 0 1 1 1 1 0 1 0 0 0 0 1 1 0 1 0 0 0 1 0 1 1 0 1 1 0\n",
      " 0 1 1 1 1 1 0 1 0 1 0 1 1 0 0 1 0 0 1 1 1 0 1 1 0 0 1 1 0 0 1 1 0 1 0 1 0\n",
      " 0 1 0 1 0 1 0 0 0 1 0 1 0 1 0 1 1 1 1 0 1 1 1 0 0 0 1 0 1 1 0 0 0 1 0 1 1\n",
      " 1 0 0 0 1 0 0 0 1 1 1 1 1 0 1 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0]\n",
      "[0 1 1 0 0 1 1 0 1 0 1 1 1 1 0 0 1 1 0 0 0 0 0 1 0 1 0 1 1 1 1 0 0 0 0 1 1\n",
      " 0 1 0 1 1 1 0 0 1 1 0 1 1 1 0 0 1 1 1 0 1 0 1 1 1 0 0 1 0 0 0 0 0 0 0 0 1\n",
      " 1 0 1 0 0 1 0 1 0 0 1 0 0 0 0 1 1 0 0 1 0 1 0 0 0 0 1 1 1 0 0 0 1 0 0 1 0\n",
      " 0 0 0 1 1 0 1 0 1 1 0 0 1 0 1 0 0 1 0 0 0 0 0 0 1 1 0 1 0 1 1 0 0 1 1 1 0\n",
      " 1 1 1 1 0 0 1 0 0 1 1 0 0 0 1 0 1 1 1 1 1 1 1 0 1 0 0 0 1 0 1 0 1 1 0 0 1\n",
      " 0 0 1 1 1 1 0 1 1 0 0 0 1 0 0 1 1 1 1 0 0 0 1 1 0 1 1 1 0 0 1 0 1 1 1 0 0\n",
      " 0 0 0 1 1 0 0 1 1 0 1 0 1 1 0 1 1 0 1 1 1 0 0 1 1 0 0 0 0 0 1 1 1 0 0 1 0\n",
      " 1 1 0 1 0 0 1 0 0 0 1 0 1 1 1 1 0 1 0 0 0 0 1 1 0 1 0 0 0 1 0 1 1 0 1 1 0\n",
      " 0 1 1 1 1 1 1 1 0 1 0 1 1 0 0 1 0 0 1 1 1 0 1 1 0 0 1 1 0 0 1 1 0 1 0 1 0\n",
      " 0 1 0 1 0 1 0 0 0 1 0 1 0 1 0 1 1 1 1 0 1 1 1 0 0 0 1 0 1 1 0 0 0 1 0 1 1\n",
      " 1 0 0 0 1 0 0 0 1 1 0 1 1 0 1 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0]\n",
      "[0 1 1 0 0 1 1 0 1 0 1 1 1 1 0 0 1 1 0 0 0 0 0 1 0 1 0 1 1 1 1 0 0 0 0 1 1\n",
      " 0 1 0 1 1 1 0 0 1 1 0 1 1 1 0 0 1 1 1 0 1 0 1 1 1 0 0 1 0 0 0 0 0 0 0 0 1\n",
      " 1 0 1 0 0 1 0 1 0 0 1 0 0 0 0 1 1 0 0 1 0 1 0 0 0 0 1 1 1 0 0 0 1 0 0 1 0\n",
      " 0 0 0 1 1 0 1 0 1 1 0 0 1 0 1 0 0 1 0 0 0 0 0 0 1 1 0 1 0 1 1 0 0 1 1 1 0\n",
      " 1 1 1 1 0 0 1 0 0 1 1 1 0 0 1 0 1 1 1 1 1 1 1 0 1 0 0 0 1 0 1 0 1 1 0 0 1\n",
      " 0 0 1 1 1 1 0 1 1 0 0 0 1 0 0 1 1 1 1 0 0 0 1 1 0 1 1 1 0 0 1 0 1 1 1 0 0\n",
      " 0 0 0 1 1 0 0 1 1 0 1 0 1 1 0 1 1 0 1 1 1 0 0 1 1 0 0 0 0 0 1 1 1 0 0 1 0\n",
      " 1 1 0 1 0 0 1 0 0 0 1 0 1 1 1 1 0 1 0 0 0 0 1 1 0 1 0 0 0 1 0 1 1 0 1 1 0\n",
      " 0 1 1 1 1 1 1 1 0 1 0 1 1 0 0 1 0 0 1 1 1 0 1 1 0 0 1 1 0 0 1 1 0 1 0 1 0\n",
      " 0 1 0 1 0 1 0 0 0 1 0 1 1 1 0 1 1 1 1 0 1 1 1 0 0 0 1 0 1 1 0 0 0 1 0 1 1\n",
      " 1 0 0 0 1 0 0 0 1 1 1 1 1 0 1 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "for n_estimators in [10, 100, 1000]:\n",
    "    #SVC\n",
    "    model3 = RandomForestClassifier(n_estimators=6)\n",
    "    model3.fit(X_train, y_train)\n",
    "    predict3 = model3.predict(X_test)\n",
    "    print(predict3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc254b3",
   "metadata": {},
   "source": [
    "# Evaluate the operation of the algorithms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b85a6819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9325\n",
      "F1-score: 0.9343065693430658\n",
      "AUC ROC: 0.9331521330694657\n"
     ]
    }
   ],
   "source": [
    "# Gaussian Naive Bayes\n",
    "from sklearn import metrics\n",
    "\n",
    "accuracy = metrics.accuracy_score(y_test, predict)\n",
    "print(\"Accuracy:\",accuracy)\n",
    "F1_score = metrics.f1_score(y_test, predict)\n",
    "print(\"F1-score:\",F1_score)\n",
    "auc_roc = metrics.roc_auc_score(y_test, predict)\n",
    "print(\"AUC ROC:\",auc_roc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c6364ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Possible values of 0.01\n",
      "Accuracy: 0.9325\n",
      "F1-score: 0.06481481481481481\n",
      "AUC ROC: 0.5167464114832536\n",
      "============\n",
      "Possible values of 0.1\n",
      "Accuracy: 0.9325\n",
      "F1-score: 0.9440389294403893\n",
      "AUC ROC: 0.9431724241589218\n",
      "============\n",
      "Possible values of 1.0\n",
      "Accuracy: 0.9325\n",
      "F1-score: 0.953995157384988\n",
      "AUC ROC: 0.9529672586988653\n",
      "============\n",
      "Possible values of 10.0\n",
      "Accuracy: 0.9325\n",
      "F1-score: 0.9437652811735943\n",
      "AUC ROC: 0.9433978807084346\n",
      "============\n",
      "Possible values of 100.0\n",
      "Accuracy: 0.9325\n",
      "F1-score: 0.9359605911330049\n",
      "AUC ROC: 0.9362208472156117\n",
      "============\n"
     ]
    }
   ],
   "source": [
    "# SVC\n",
    "for num in  [1e-02, 1e-01, 1e00, 1e01, 1e02]:\n",
    "    model2 = SVC(num, kernel='rbf', gamma=0.1)\n",
    "    model2.fit(X_train, y_train)\n",
    "    predict2 = model2.predict(X_test)\n",
    "    print(\"Possible values of \" + str(num))\n",
    "    accurary = metrics.accuracy_score(y_test, predict2)\n",
    "    print(\"Accuracy:\",accuracy)\n",
    "    F1_score = metrics.f1_score(y_test, predict2)\n",
    "    print(\"F1-score:\",F1_score)\n",
    "    auc_roc = metrics.roc_auc_score(y_test, predict2)\n",
    "    print(\"AUC ROC:\",auc_roc)\n",
    "    print(\"============\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b071c63e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "possible 10 value estimators\n",
      "Accuracy: 0.9525\n",
      "F1-score: 0.953771289537713\n",
      "AUC ROC: 0.953192715248378\n",
      "============\n",
      "possible 100 value estimators\n",
      "Accuracy: 0.9525\n",
      "F1-score: 0.953771289537713\n",
      "AUC ROC: 0.953192715248378\n",
      "============\n",
      "possible 1000 value estimators\n",
      "Accuracy: 0.9575\n",
      "F1-score: 0.9584352078239609\n",
      "AUC ROC: 0.9584283173426187\n",
      "============\n"
     ]
    }
   ],
   "source": [
    "# RandomForestClassifier:\n",
    "\n",
    "for n_estimators in [10, 100, 1000]:\n",
    "    model3 = RandomForestClassifier(n_estimators=6)\n",
    "    model3.fit(X_train, y_train)\n",
    "    predict3 = model3.predict(X_test)\n",
    "    \n",
    "    print(\"possible \" + str(n_estimators) + \" value estimators\")\n",
    "    accuracy = metrics.accuracy_score(y_test, predict3)\n",
    "    print(\"Accuracy:\",accuracy)\n",
    "    F1_score = metrics.f1_score(y_test, predict3)\n",
    "    print(\"F1-score:\",F1_score)\n",
    "    auc_roc = metrics.roc_auc_score(y_test, predict3)\n",
    "    print(\"AUC ROC:\",auc_roc)\n",
    "    print(\"============\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c244de3f",
   "metadata": {},
   "source": [
    "#### Dandy Wibowo (334541)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
